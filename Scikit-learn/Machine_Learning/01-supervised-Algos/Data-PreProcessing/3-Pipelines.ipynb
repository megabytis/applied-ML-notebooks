{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9dadbae",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Pipelines in Machine Learning\n",
    "\n",
    "## üß† What‚Äôs the Problem?\n",
    "\n",
    "So far, every time we trained a model, we had to do this manually:\n",
    "\n",
    "1. Encode categorical data  \n",
    "2. Scale numerical features  \n",
    "3. Split data  \n",
    "4. Train model  \n",
    "5. Predict  \n",
    "\n",
    "But in real workflows:\n",
    "- **We don‚Äôt wanna repeat all these steps** for every dataset.\n",
    "- **Risk of data leakage**: For example, accidentally using test data in `.fit()` during scaling.\n",
    "\n",
    "That‚Äôs where **Pipelines** come in.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° What is a Pipeline?\n",
    "\n",
    "A **Pipeline** in `sklearn` chains all preprocessing + modeling steps together in a single workflow.\n",
    "\n",
    "Think of it as a **conveyor belt** ‚Äî raw data goes in, predictions come out.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Why Use Pipelines?\n",
    "\n",
    "1. **Automation**: Automate repetitive tasks like encoding, scaling, and training.\n",
    "2. **Avoid Data Leakage**: Ensures that preprocessing (e.g., scaling) only uses training data.\n",
    "3. **Clean Code**: Keeps your code organized and reproducible.\n",
    "4. **Easy to Deploy**: Simplifies the process of deploying models into production.\n",
    "\n",
    "---\n",
    "\n",
    "## üåü How Does It Work?\n",
    "\n",
    "A Pipeline consists of multiple steps, each defined as a tuple `(name, transformer/model)`:\n",
    "- **Transformers**: Handle preprocessing steps like encoding or scaling.\n",
    "- **Model**: The final step is always an estimator (e.g., LogisticRegression).\n",
    "\n",
    "Example Workflow:\n",
    "1. **Step 1**: Encode categorical variables.\n",
    "2. **Step 2**: Scale numerical features.\n",
    "3. **Step 3**: Train a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85ddc0",
   "metadata": {},
   "source": [
    "## Without Pipelines üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3feb2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import  load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0ecbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba542d",
   "metadata": {},
   "source": [
    "## With Pipelines üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e02a5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d83ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Loading dataset\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Creating pipeline\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", LogisticRegression())])\n",
    "\n",
    "# Train\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_predict = pipe.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e254d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
