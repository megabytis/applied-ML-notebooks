{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4c44d8",
   "metadata": {},
   "source": [
    "# üìä Naive Bayes Classifier\n",
    "\n",
    "## üåü Real-Life Example: The Weather & Golf Decision\n",
    "\n",
    "Imagine you're **Tom**, and every morning you decide whether to play golf based on the weather. You've kept a diary for 14 days:\n",
    "\n",
    "| Day | Outlook   | Temperature | Humidity | Windy | Play Golf? |\n",
    "|-----|-----------|-------------|----------|-------|------------|\n",
    "| 1   | Rainy     | Hot         | High     | No    | ‚ùå No      |\n",
    "| 2   | Rainy     | Hot         | High     | Yes   | ‚ùå No      |\n",
    "| 3   | Overcast  | Hot         | High     | No    | ‚úÖ Yes     |\n",
    "| 4   | Sunny     | Mild        | High     | No    | ‚úÖ Yes     |\n",
    "| 5   | Sunny     | Cool        | Normal   | No    | ‚úÖ Yes     |\n",
    "| 6   | Sunny     | Cool        | Normal   | Yes   | ‚ùå No      |\n",
    "| 7   | Overcast  | Cool        | Normal   | Yes   | ‚úÖ Yes     |\n",
    "| 8   | Rainy     | Mild        | High     | No    | ‚ùå No      |\n",
    "| 9   | Rainy     | Cool        | Normal   | No    | ‚úÖ Yes     |\n",
    "| 10  | Sunny     | Mild        | Normal   | No    | ‚úÖ Yes     |\n",
    "| 11  | Rainy     | Mild        | Normal   | Yes   | ‚úÖ Yes     |\n",
    "| 12  | Overcast  | Mild        | High     | Yes   | ‚úÖ Yes     |\n",
    "| 13  | Overcast  | Hot         | Normal   | No    | ‚úÖ Yes     |\n",
    "| 14  | Sunny     | Mild        | High     | Yes   | ‚ùå No      |\n",
    "\n",
    "**Today's weather**: Sunny, Hot, Normal humidity, No wind  \n",
    "**Question**: Should Tom play golf today?\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Step 1: What Would a Smart Person Do?\n",
    "\n",
    "A smart person would look at their diary and ask:\n",
    "- \"On **sunny** days, how often did I play golf?\"\n",
    "- \"When it was **hot**, how often did I play?\"\n",
    "- \"With **normal humidity**, what happened?\"\n",
    "- \"When it was **not windy**, what was the outcome?\"\n",
    "\n",
    "Then they'd combine all this information to make a decision.\n",
    "\n",
    "**This is exactly what Naive Bayes does!**\n",
    "\n",
    "---\n",
    "## üìê Bayes' Theorem\n",
    "\n",
    "### Definition of Conditional Probability:\n",
    "$$\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
    "$$\n",
    "\n",
    "### Bayes' Theorem:\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "- $P(A|B)$: Probability of A given B (posterior)\n",
    "- $P(B|A)$: Probability of B given A (likelihood)  \n",
    "- $P(A)$: Prior probability of A (prior)\n",
    "- $P(B)$: Total probability of B (evidence)\n",
    "- $P(A \\cap B)$: Probability of both A and B occurring together\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ Step 2: Let's Count From the Diary\n",
    "\n",
    "### Overall Statistics:\n",
    "- **Total days**: 14\n",
    "- **Played golf (Yes)**: 9 days ‚Üí P(Yes) = 9/14 ‚âà 0.64\n",
    "- **Didn't play (No)**: 5 days ‚Üí P(No) = 5/14 ‚âà 0.36\n",
    "\n",
    "### For \"Sunny\" Outlook:\n",
    "- **Sunny days**: 5 total (Days 4, 5, 6, 10, 14)\n",
    "- **Sunny + Played**: 3 days (Days 4, 5, 10) ‚Üí P(Sunny | Yes) = 3/9 = 0.33\n",
    "   - golf played days in sunny days / total golf played days\n",
    "   - i.e. probability of sunny days given that golf is played .\n",
    "\n",
    "- **Sunny + Didn't Play**: 2 days (Days 6, 14) ‚Üí P(Sunny | No) = 2/5 = 0.40\n",
    "   - probability of sunny days given that golf is not played\n",
    "\n",
    "### For \"Hot\" Temperature:\n",
    "- **Hot days**: 4 total (Days 1, 2, 3, 13)\n",
    "- **Hot + Played**: 2 days (Days 3, 13) ‚Üí P(Hot | Yes) = 2/9 ‚âà 0.22\n",
    "- **Hot + Didn't Play**: 2 days (Days 1, 2) ‚Üí P(Hot | No) = 2/5 = 0.40\n",
    "\n",
    "### For \"Normal\" Humidity:\n",
    "- **Normal humidity days**: 7 total\n",
    "- **Normal + Played**: 6 days ‚Üí P(Normal | Yes) = 6/9 ‚âà 0.67\n",
    "- **Normal + Didn't Play**: 1 day ‚Üí P(Normal | No) = 1/5 = 0.20\n",
    "\n",
    "### For \"No Wind\":\n",
    "- **No wind days**: 8 total\n",
    "- **No wind + Played**: 6 days ‚Üí P(No Wind | Yes) = 6/9 ‚âà 0.67\n",
    "- **No wind + Didn't Play**: 2 days ‚Üí P(No Wind | No) = 2/5 = 0.40\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Step 3: The \"Naive\" Assumption\n",
    "\n",
    "Here's the key insight: **Naive Bayes assumes each weather condition is independent**.\n",
    "\n",
    "This means:\n",
    "- Whether it's sunny doesn't affect whether it's hot\n",
    "- Humidity doesn't depend on wind\n",
    "- Each condition gives separate evidence\n",
    "\n",
    "**In reality, this isn't true** (sunny days are often hot), but it makes the math simple and still works well!\n",
    "\n",
    "So instead of calculating P(Sunny AND Hot AND Normal AND No Wind | Yes), we calculate:\n",
    "\n",
    "P(Sunny | Yes) √ó P(Hot | Yes) √ó P(Normal | Yes) √ó P(No Wind | Yes)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Step 4: Calculate the Scores\n",
    "\n",
    "### Score for \"Play Golf = YES\":\n",
    "\n",
    "P(Yes) √ó P(Sunny | Yes) √ó P(Hot | Yes) √ó P(Normal | Yes) √ó P(No Wind | Yes)\n",
    "\n",
    "= 0.64 √ó 0.33 √ó 0.22 √ó 0.67 √ó 0.67\n",
    "\n",
    "‚âà 0.64 √ó 0.033\n",
    "\n",
    "‚âà 0.021\n",
    "\n",
    "\n",
    "### Score for \"Play Golf = NO\":\n",
    "\n",
    "P(No) √ó P(Sunny | No) √ó P(Hot | No) √ó P(Normal | No) √ó P(No Wind | No)\n",
    "\n",
    "= 0.36 √ó 0.40 √ó 0.40 √ó 0.20 √ó 0.40\n",
    "\n",
    "= 0.36 √ó 0.0128\n",
    "\n",
    "‚âà 0.0046\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## üèÜ Step 5: Make the Decision\n",
    "\n",
    "- **YES score**: 0.021\n",
    "- **NO score**: 0.0046\n",
    "\n",
    "Since **0.021 > 0.0046**, Naive Bayes predicts: **‚úÖ PLAY GOLF!**\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Connecting to Technical Terms\n",
    "\n",
    "### What We Just Did = Naive Bayes Algorithm\n",
    "\n",
    "1. **Bayes' Theorem**: \n",
    "   - We calculated P(Class | Features) using P(Features | Class) √ó P(Class)\n",
    "   - This is the core of Bayes' theorem\n",
    "\n",
    "2. **\"Naive\" Assumption**: \n",
    "   - We assumed P(Feature1 AND Feature2 | Class) = P(Feature1 | Class) √ó P(Feature2 | Class)\n",
    "   - This independence assumption is why it's called \"naive\"\n",
    "\n",
    "3. **Prior Probability**: \n",
    "   - P(Yes) = 0.64 and P(No) = 0.36 are called \"priors\"\n",
    "   - They represent our initial belief before seeing today's weather\n",
    "\n",
    "4. **Likelihood**: \n",
    "   - P(Sunny | Yes) = 0.33 is the \"likelihood\"\n",
    "   - It tells us how likely sunny weather is given that we played golf\n",
    "\n",
    "5. **Posterior Probability**: \n",
    "   - The final scores (0.021 and 0.0046) are proportional to \"posterior probabilities\"\n",
    "   - We choose the class with the highest posterior\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ How This Works for Any Problem\n",
    "\n",
    "### General Formula:\n",
    "For any new example with features [F1, F2, F3, ..., Fn]:\n",
    "\n",
    "Score for Class C = P(C) √ó P(F1 | C) √ó P(F2 | C) √ó ... √ó P(Fn | C)\n",
    "\n",
    "\n",
    "\n",
    "### For Different Data Types:\n",
    "\n",
    "#### **Text Classification (Spam Detection)**:\n",
    "- Features = words in email\n",
    "- P(\"FREE\" | Spam) = how often \"FREE\" appears in spam emails\n",
    "- P(\"meeting\" | Ham) = how often \"meeting\" appears in legitimate emails\n",
    "\n",
    "#### **Medical Diagnosis**:\n",
    "- Features = symptoms (fever, cough, headache)\n",
    "- P(Fever | Flu) = how often fever occurs with flu\n",
    "- P(Cough | Common Cold) = how often cough occurs with common cold\n",
    "\n",
    "#### **Product Reviews**:\n",
    "- Features = words in review\n",
    "- P(\"excellent\" | Positive) = how often \"excellent\" appears in positive reviews\n",
    "- P(\"terrible\" | Negative) = how often \"terrible\" appears in negative reviews\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è The Zero Probability Problem\n",
    "\n",
    "### What if a word never appeared?\n",
    "Imagine in your golf diary, you never had a \"Sunny + Hot + Normal + No Wind\" combination.\n",
    "\n",
    "**Problem**: If any P(Feature | Class) = 0, the entire score becomes 0!\n",
    "\n",
    "### Solution: Laplace Smoothing\n",
    "Instead of counting raw frequencies, we add 1 to every count:\n",
    "\n",
    "**Original**: P(Sunny | Yes) = 3/9  \n",
    "**With smoothing**: P(Sunny | Yes) = (3+1)/(9+3) = 4/12 = 0.33\n",
    "\n",
    "Where \"3\" is the number of possible outlook values (Sunny, Rainy, Overcast).\n",
    "\n",
    "This ensures no probability is ever zero!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Why Naive Bayes Works So Well\n",
    "\n",
    "### The Secret Sauce:\n",
    "1. **It doesn't need perfect independence** ‚Äì even if features are somewhat related, the relative scores still work\n",
    "2. **It focuses on the biggest patterns** ‚Äì small errors in individual probabilities cancel out\n",
    "3. **It's incredibly fast** ‚Äì just counting and multiplying\n",
    "4. **It works with small data** ‚Äì you don't need millions of examples\n",
    "\n",
    "### When It's Perfect:\n",
    "- **Text classification**: Words in documents are somewhat independent\n",
    "- **Real-time decisions**: Email spam filtering, chatbot responses\n",
    "- **Baseline models**: Quick first attempt before complex models\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Key Takeaways\n",
    "\n",
    "- **Naive Bayes = Smart counting + Simple math**\n",
    "- **\"Naive\" = assumes features are independent** (simplification that works)\n",
    "- **Works by calculating scores for each class** and picking the highest\n",
    "- **Perfect for text problems** like spam detection and sentiment analysis\n",
    "- **Handles the \"never seen before\" problem** with Laplace smoothing\n",
    "- **Fast, simple, and surprisingly accurate**\n",
    "\n",
    "> **Remember**: Naive Bayes is like your friend who makes decisions by looking at past patterns and saying \"Based on what I've seen before, this is most likely what will happen!\" üéØ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e791542",
   "metadata": {},
   "source": [
    "### Types of Naive Bayes\n",
    "| Type | Use-case | Data Type |\n",
    "|------|-----------|-----------|\n",
    "| GaussianNB | Continuous | Real numbers |\n",
    "| MultinomialNB | Discrete counts | Word frequency |\n",
    "| BernoulliNB | Binary | Word presence (0/1) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
