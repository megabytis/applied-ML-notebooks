{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ad9e0d",
   "metadata": {},
   "source": [
    "## What are Hyperparameters?\n",
    "\n",
    "ðŸ‘‰ These are **the settings you choose before training** a model.\n",
    "They **control** how the model learns â€” not learned automatically.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* For `DecisionTreeClassifier`:\n",
    "\n",
    "  * `max_depth`, `min_samples_split`, `criterion`\n",
    "* For `KNeighborsClassifier`:\n",
    "\n",
    "  * `n_neighbors`, `weights`, `metric`\n",
    "* For `SVM`:\n",
    "\n",
    "  * `C`, `kernel`, `gamma`\n",
    "\n",
    "Think of hyperparameters like the **\"knobs\"** you tune on a machine before running it.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Grid Search?\n",
    "\n",
    "Normally, weâ€™d guess:\n",
    "\n",
    "```python\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "```\n",
    "\n",
    "But what if `max_depth=5` or `min_samples_split=4` gives better accuracy?\n",
    "\n",
    "Thatâ€™s where **GridSearchCV** comes in. It tries **every possible combination** of parameters you give, trains the model on each, and picks the best one based on performance (using cross-validation internally).\n",
    "\n",
    "---\n",
    "\n",
    "## Real-life Analogy\n",
    "\n",
    "Think of tuning your model like finding the best gym routine:\n",
    "You test combinations like:\n",
    "\n",
    "* Split type (Push/Pull/Legs)\n",
    "* Reps (8, 10, 12)\n",
    "* Rest time (30s, 60s, 90s)\n",
    "\n",
    "You run all combos for a week â†’ track results â†’ pick the one that gives best gains.\n",
    "Thatâ€™s literally **Grid Search**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a54f47",
   "metadata": {},
   "source": [
    "## Example â€” Decision Tree Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab0f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641824dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04b633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5224cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "}\n",
    "\n",
    "# Grid Search with 5-fold CV\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52a7d4",
   "metadata": {},
   "source": [
    "**Output example:**\n",
    "\n",
    "```\n",
    "Best Parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
    "Best Accuracy: 0.9666\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Behind the scenes\n",
    "\n",
    "GridSearchCV does this under the hood:\n",
    "\n",
    "* For each combo of parameters â†’ Train using **5-fold cross-validation**\n",
    "* Store the average accuracy\n",
    "* Pick the highest-performing combo\n",
    "\n",
    "So if your grid has 5 Ã— 3 Ã— 2 = 30 combos â†’\n",
    "Thatâ€™s 30 Ã— 5 = **150 total model trainings** âš™ï¸\n",
    "\n",
    "Thatâ€™s why GridSearch is powerful but **computationally expensive**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Step 4: How to use the best model\n",
    "\n",
    "```python\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§° Quick Tips\n",
    "\n",
    "| Tip                       | Description                                     |\n",
    "| ------------------------- | ----------------------------------------------- |\n",
    "| âœ… Use small grid first    | Donâ€™t test 1000 combos on first run             |\n",
    "| âš¡ Use `n_jobs=-1`         | To use all CPU cores for faster search          |\n",
    "| ðŸ’¡ Combine with Pipelines | You can optimize preprocessing + model together |\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ TL;DR\n",
    "\n",
    "> ðŸ”¹ Grid Search = brute-force tuning\n",
    "> ðŸ”¹ Tries all combinations\n",
    "> ðŸ”¹ Finds the most optimal hyperparameters\n",
    "> ðŸ”¹ Expensive but accurate\n",
    "\n",
    "---\n",
    "\n",
    "Next up â†’ **Randomized Search**, a faster version of Grid Search that *samples intelligently* instead of testing every combo.\n",
    "\n",
    "Wanna jump into **Randomized SearchCV** next?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
