{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ad9e0d",
   "metadata": {},
   "source": [
    "## What are Hyperparameters?\n",
    "\n",
    "ðŸ‘‰ These are **the settings you choose before training** a model.\n",
    "They **control** how the model learns â€” not learned automatically.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* For `DecisionTreeClassifier`:\n",
    "\n",
    "  * `max_depth`, `min_samples_split`, `criterion`\n",
    "* For `KNeighborsClassifier`:\n",
    "\n",
    "  * `n_neighbors`, `weights`, `metric`\n",
    "* For `SVM`:\n",
    "\n",
    "  * `C`, `kernel`, `gamma`\n",
    "\n",
    "Think of hyperparameters like the **\"knobs\"** you tune on a machine before running it.\n",
    "\n",
    "---\n",
    "## **1. GridSearchCV**\n",
    "### Why Grid Search?\n",
    "\n",
    "Normally, weâ€™d guess:\n",
    "\n",
    "```python\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "```\n",
    "\n",
    "But what if `max_depth=5` or `min_samples_split=4` gives better accuracy?\n",
    "\n",
    "Thatâ€™s where **GridSearchCV** comes in. It tries **every possible combination** of parameters you give, trains the model on each, and picks the best one based on performance (using cross-validation internally).\n",
    "\n",
    "---\n",
    "\n",
    "## Real-life Analogy\n",
    "\n",
    "Think of tuning your model like finding the best gym routine:\n",
    "You test combinations like:\n",
    "\n",
    "* Split type (Push/Pull/Legs)\n",
    "* Reps (8, 10, 12)\n",
    "* Rest time (30s, 60s, 90s)\n",
    "\n",
    "You run all combos for a week â†’ track results â†’ pick the one that gives best gains.\n",
    "Thatâ€™s literally **Grid Search**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a54f47",
   "metadata": {},
   "source": [
    "## Example â€” Decision Tree Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab0f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641824dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04b633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5224cc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2}\n",
      "Best Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "}\n",
    "\n",
    "# Grid Search with 5-fold CV\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec52a7d4",
   "metadata": {},
   "source": [
    "**Output example:**\n",
    "\n",
    "```\n",
    "Best Parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 2}\n",
    "Best Accuracy: 0.9666\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Behind the scenes\n",
    "\n",
    "GridSearchCV does this under the hood:\n",
    "\n",
    "* For each combo of parameters â†’ Train using **5-fold cross-validation**\n",
    "* Store the average accuracy\n",
    "* Pick the highest-performing combo\n",
    "\n",
    "So if your grid has 5 Ã— 3 Ã— 2 = 30 combos â†’\n",
    "Thatâ€™s 30 Ã— 5 = **150 total model trainings** âš™ï¸\n",
    "\n",
    "Thatâ€™s why GridSearch is powerful but **computationally expensive**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª Step 4: How to use the best model\n",
    "\n",
    "```python\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§° Quick Tips\n",
    "\n",
    "| Tip                       | Description                                     |\n",
    "| ------------------------- | ----------------------------------------------- |\n",
    "| âœ… Use small grid first    | Donâ€™t test 1000 combos on first run             |\n",
    "| âš¡ Use `n_jobs=-1`         | To use all CPU cores for faster search          |\n",
    "| ðŸ’¡ Combine with Pipelines | You can optimize preprocessing + model together |\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ TL;DR\n",
    "\n",
    "> ðŸ”¹ Grid Search = brute-force tuning\n",
    "> ðŸ”¹ Tries all combinations\n",
    "> ðŸ”¹ Finds the most optimal hyperparameters\n",
    "> ðŸ”¹ Expensive but accurate\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b793f3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **2. RandomizedSearchCV**\n",
    "\n",
    "### Grid Search vs Randomized Search\n",
    "\n",
    "| Feature              | GridSearchCV                          | RandomizedSearchCV                       |\n",
    "| -------------------- | ------------------------------------- | ---------------------------------------- |\n",
    "| **Approach**         | Tests **every** parameter combination | Tests **random samples** of combinations |\n",
    "| **Speed**            | Very slow (brute-force)               | Much faster (samples randomly)           |\n",
    "| **Best for**         | Small grids / fewer parameters        | Large grids / expensive models           |\n",
    "| **Accuracy**         | Precise but computationally heavy     | Approximate but efficient                |\n",
    "| **Example use case** | Decision Tree, Logistic Regression    | Random Forest, XGBoost, SVM              |\n",
    "\n",
    "So when your model has **many tunable parameters**, Grid Search becomes overkill.\n",
    "Thatâ€™s where RandomizedSearchCV shines ðŸš€\n",
    "\n",
    "---\n",
    "\n",
    "## Real-life Analogy\n",
    "\n",
    "Grid Search â†’ trying **every** protein shake recipe in the world ðŸŒðŸ«ðŸ¥­ðŸ¥¤\n",
    "Randomized Search â†’ trying **20 random ones** and picking the best â€” much faster and you still find something awesome.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ac65941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4507bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0525789",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bbadbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 156}\n",
      "Best Accuracy: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": randint(50, 200),\n",
    "    \"max_depth\": randint(2, 10),\n",
    "    \"min_samples_split\": randint(2, 10),\n",
    "    \"min_samples_leaf\": randint(1, 5),\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "# Randomized Search\n",
    "rand_search = RandomizedSearchCV(\n",
    "    model_2,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # number of random combos to try\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "rand_search.fit(X, y)\n",
    "\n",
    "print(\"Best Params:\", rand_search.best_params_)\n",
    "print(\"Best Accuracy:\", rand_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeee671d",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "```\n",
    "Best Params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 156}\n",
    "Best Accuracy: 0.9666666666666668\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Key Parameters\n",
    "\n",
    "| Parameter             | Meaning                                  |\n",
    "| --------------------- | ---------------------------------------- |\n",
    "| `param_distributions` | dict or scipy.stats distributions        |\n",
    "| `n_iter`              | how many random combos to test           |\n",
    "| `cv`                  | folds for cross-validation               |\n",
    "| `scoring`             | metric (e.g., accuracy, f1)              |\n",
    "| `n_jobs=-1`           | use all CPU cores for faster computation |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  When to Use Which\n",
    "\n",
    "* Use **GridSearchCV** when you have few hyperparameters and want **precise tuning**.\n",
    "* Use **RandomizedSearchCV** when you have **many parameters** and need **speed + efficiency**.\n",
    "\n",
    "---\n",
    "\n",
    "## âš¡ TL;DR\n",
    "\n",
    "> ðŸ”¹ Both GridSearchCV & RandomizedSearchCV = hyperparameter tuning tools.\n",
    "\n",
    "> ðŸ”¹ GridSearch = exhaustive, precise, but slow.\n",
    "\n",
    "> ðŸ”¹ RandomizedSearch = faster, efficient, and surprisingly accurate.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
