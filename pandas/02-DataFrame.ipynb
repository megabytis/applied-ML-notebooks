{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c00d3d69",
   "metadata": {},
   "source": [
    "## 1. Introduction to DataFrame\n",
    "\n",
    "- A DataFrame is a 2D tabular structure (rows Ã— columns).\n",
    "\n",
    "- Think of it as:\n",
    "\n",
    "    - Excel sheet in Python.\n",
    "\n",
    "    - SQL table in memory.\n",
    "\n",
    "    - Dataset weâ€™ll feed to ML models.\n",
    "\n",
    "- Why important in ML?\n",
    "    - Most datasets (CSV, JSON, SQL dumps) are read into Pandas DataFrames before cleaning, analyzing, and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "580ff55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da3472",
   "metadata": {},
   "source": [
    "## 2. Creating DataFrames\n",
    "\n",
    "- From a dictionary of lists/arrays.\n",
    "\n",
    "- From list of dicts.\n",
    "\n",
    "- From NumPy arrays.\n",
    "\n",
    "- From Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "312d79c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dict of lists\n",
    "df1 = pd.DataFrame({\n",
    "    \"Name\": [\"A\", \"B\", \"C\"],\n",
    "    \"Age\": [21, 22, 23],\n",
    "    \"Score\": [85, 90, 95]\n",
    "})\n",
    "\n",
    "# From list of dicts\n",
    "df2 = pd.DataFrame([\n",
    "    {\"Name\": \"A\", \"Age\": 21, \"Score\": 85},\n",
    "    {\"Name\": \"B\", \"Age\": 22, \"Score\": 90}\n",
    "])\n",
    "\n",
    "# From NumPy array\n",
    "arr = np.arange(9).reshape(3,3)\n",
    "df3 = pd.DataFrame(arr, columns=[\"A\",\"B\",\"C\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bef950",
   "metadata": {},
   "source": [
    "## 3. Inspecting a DataFrame\n",
    "\n",
    "- Now that we can create DataFrames, the next skill is looking inside them quickly.\n",
    "In ML, when we load a dataset (say, 10k rows), we wonâ€™t scroll through everything. Instead, weâ€™ll peek, summarize, and sanity-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a4426f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Name    3 non-null      object\n",
      " 1   Age     3 non-null      int64 \n",
      " 2   Score   3 non-null      int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.5</td>\n",
       "      <td>87.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.5</td>\n",
       "      <td>92.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Score\n",
       "count   3.0    3.0\n",
       "mean   22.0   90.0\n",
       "std     1.0    5.0\n",
       "min    21.0   85.0\n",
       "25%    21.5   87.5\n",
       "50%    22.0   90.0\n",
       "75%    22.5   92.5\n",
       "max    23.0   95.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()       # first 5 rows\n",
    "df1.tail(3)      # last 3 rows\n",
    "df1.shape        # (rows, cols)\n",
    "df1.columns      # column names\n",
    "df1.info()       # data types + memory usage\n",
    "df1.describe()   # summary stats\n",
    "\n",
    "# ðŸ”‘ ML relevance: info() helps spot categorical vs numerical, missing data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a295153",
   "metadata": {},
   "source": [
    "## 4. Selecting Data\n",
    "\n",
    "- Column selection: df[\"col\"], df[[\"col1\",\"col2\"]]\n",
    "\n",
    "- Row selection: df.loc[rows, cols], df.iloc[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb619ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(21)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Name\"]            # Single column\n",
    "df1[[\"Name\", \"Age\"]]   # Multiple columns\n",
    "\n",
    "df1.loc[0]             # First row (by label)\n",
    "df1.iloc[0]            # First row (by index position)\n",
    "df1.loc[0, \"Age\"]      # Specific cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef8b8d",
   "metadata": {},
   "source": [
    "## 5. Filtering & Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f260910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>23</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name  Age  Score\n",
       "1    B   22     90\n",
       "2    C   23     95"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1[\"Age\"] > 21]              # filter\n",
    "df1[(df1[\"Age\"] > 21) & (df1[\"Score\"] > 85)]  # multiple conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb0210",
   "metadata": {},
   "source": [
    "## 6. Adding / Modifying Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2a7418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Pass\"] = df1[\"Score\"] > 80\n",
    "df1[\"DoubleAge\"] = df1[\"Age\"] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7afe6",
   "metadata": {},
   "source": [
    "## 7. Dropping Rows/Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e53325b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(\"DoubleAge\", axis=1, inplace=True)  # drop column\n",
    "df1.drop(1, axis=0, inplace=True)            # drop row\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745e1b1",
   "metadata": {},
   "source": [
    "## 8. Handling Missing Data (Critical for ML ðŸš¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2b39fa93",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert ['AC'] to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df1.isna().sum()                \u001b[38;5;66;03m# count missing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df1.fillna(\u001b[43mdf1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# fill with mean\u001b[39;00m\n\u001b[32m      3\u001b[39m df1.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)        \u001b[38;5;66;03m# drop rows with NaN\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ðŸ”‘ ML relevance: Missing values break ML models â€” weâ€™ll fix them here.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/frame.py:11700\u001b[39m, in \u001b[36mDataFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  11692\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n\u001b[32m  11693\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  11694\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  11698\u001b[39m     **kwargs,\n\u001b[32m  11699\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m11700\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11701\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[32m  11702\u001b[39m         result = result.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/generic.py:12439\u001b[39m, in \u001b[36mNDFrame.mean\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(\n\u001b[32m  12433\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12434\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12437\u001b[39m     **kwargs,\n\u001b[32m  12438\u001b[39m ) -> Series | \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m> \u001b[39m\u001b[32m12439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12440\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m  12441\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/generic.py:12396\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12392\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12394\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/frame.py:11569\u001b[39m, in \u001b[36mDataFrame._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m  11565\u001b[39m     df = df.T\n\u001b[32m  11567\u001b[39m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[32m  11568\u001b[39m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[32m> \u001b[39m\u001b[32m11569\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m  11570\u001b[39m out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001b[32m0\u001b[39m]\n\u001b[32m  11571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out.dtype != \u001b[33m\"\u001b[39m\u001b[33mboolean\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/internals/managers.py:1500\u001b[39m, in \u001b[36mBlockManager.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m   1498\u001b[39m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] = []\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.blocks:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m     nbs = \u001b[43mblk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m     res_blocks.extend(nbs)\n\u001b[32m   1503\u001b[39m index = Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/internals/blocks.py:406\u001b[39m, in \u001b[36mBlock.reduce\u001b[39m\u001b[34m(self, func)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ndim == \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.values.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    409\u001b[39m         res_values = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/frame.py:11488\u001b[39m, in \u001b[36mDataFrame._reduce.<locals>.blk_func\u001b[39m\u001b[34m(values, axis)\u001b[39m\n\u001b[32m  11486\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.array([result])\n\u001b[32m  11487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m> \u001b[39m\u001b[32m11488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/nanops.py:720\u001b[39m, in \u001b[36mnanmean\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m    718\u001b[39m count = _get_counts(values.shape, mask, axis, dtype=dtype_count)\n\u001b[32m    719\u001b[39m the_sum = values.sum(axis, dtype=dtype_sum)\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m the_sum = \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    723\u001b[39m     count = cast(np.ndarray, count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/pandas/core/nanops.py:1686\u001b[39m, in \u001b[36m_ensure_numeric\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1683\u001b[39m inferred = lib.infer_dtype(x)\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inferred \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1686\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to numeric\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1688\u001b[39m     x = x.astype(np.complex128)\n",
      "\u001b[31mTypeError\u001b[39m: Could not convert ['AC'] to numeric"
     ]
    }
   ],
   "source": [
    "df1.isna().sum()                # count missing\n",
    "df1.fillna(df1.mean(), inplace=True)  # fill with mean\n",
    "df1.dropna(inplace=True)        # drop rows with NaN\n",
    "\n",
    "# ðŸ”‘ ML relevance: Missing values break ML models â€” weâ€™ll fix them here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07823961",
   "metadata": {},
   "source": [
    "## 9. Aggregations & GroupBy (Split â†’ Apply â†’ Combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9613e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby(\"Name\")[\"Score\"].mean()\n",
    "df1.groupby(\"Name\").agg({\"Score\": [\"mean\",\"max\"], \"Age\": \"min\"})\n",
    "\n",
    "# ðŸ”‘ Used for summarizing datasets before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9cb86",
   "metadata": {},
   "source": [
    "## 10. Sorting & Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"Age\")         # ascending\n",
    "df.sort_values(by=\"Salary\", ascending=False)\n",
    "df.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbf59b",
   "metadata": {},
   "source": [
    "## 11. Merge, Join, Concat (SQL-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bfb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.DataFrame({\"ID\": [1,2], \"Name\": [\"A\",\"B\"]})\n",
    "df_b = pd.DataFrame({\"ID\": [1,2], \"Score\": [85,90]})\n",
    "\n",
    "pd.merge(df_a, df_b, on=\"ID\", how=\"inner\")   # SQL-style joins\n",
    "pd.concat([df_a, df_b], axis=0)              # stacking rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d13f77",
   "metadata": {},
   "source": [
    "## 11. Apply, Map, Applymap (Custom Ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to column\n",
    "df1[\"Age\"].apply(lambda x: x+1)\n",
    "\n",
    "# Apply element-wise to Series\n",
    "df1[\"Name\"].map(str.upper)\n",
    "\n",
    "# Apply to entire DataFrame\n",
    "df1.applymap(lambda x: str(x).upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0b5a81",
   "metadata": {},
   "source": [
    "## 12. String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45475853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"Name\"].str.lower()\n",
    "df1[\"Name\"].str.contains(\"a\")\n",
    "# ðŸ”‘ Useful for cleaning messy text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc0deb",
   "metadata": {},
   "source": [
    "## 13. Datetime Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f02915e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dates = pd.DataFrame({\n",
    "    \"date\": pd.to_datetime([\"2021-01-01\", \"2021-06-01\"])\n",
    "})\n",
    "df_dates[\"year\"] = df_dates[\"date\"].dt.year\n",
    "\n",
    "# ðŸ”‘ Essential for time-series ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb199e6",
   "metadata": {},
   "source": [
    "## 14. Handling Categorical & Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba273c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Department\"].unique()       # unique categories\n",
    "df[\"Department\"].value_counts() # frequency\n",
    "df[\"Department\"].astype(\"category\")\n",
    "\n",
    "# String ops\n",
    "df[\"Name\"].str.upper()\n",
    "df[\"Name\"].str.contains(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60a143",
   "metadata": {},
   "source": [
    "## 15. Indexing Tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Name\", inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.rename(columns={\"Salary\":\"Income\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e0822",
   "metadata": {},
   "source": [
    "## 16. Importing & Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV\n",
    "pd.read_csv(\"data.csv\")\n",
    "df.to_csv(\"output.csv\", index=False)\n",
    "\n",
    "# Excel\n",
    "pd.read_excel(\"data.xlsx\")\n",
    "df.to_excel(\"output.xlsx\", index=False)\n",
    "\n",
    "# JSON\n",
    "pd.read_json(\"data.json\")\n",
    "df.to_json(\"output.json\", orient=\"records\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
