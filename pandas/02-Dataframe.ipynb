{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c1193",
   "metadata": {},
   "source": [
    "- #### Pandas DataFrames are two-dimensional data structures with labeled rows and columns, that can hold many data types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ffbecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataframe\n",
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6], \"C\": [7, 8, 9]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e76c8",
   "metadata": {},
   "source": [
    "## Axes :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding Axes\n",
    "df.sum()  # it sums down 0 axis (rows)\n",
    "df.sum(axis=0)  # same as before, sums down 0 axis (cuz axis=0 is default)\n",
    "df.sum(axis=1)  # sums across the 1 axis (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2fc17",
   "metadata": {},
   "source": [
    "## Loading Data into DF :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a14f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into DF\n",
    "df = pd.read_csv(\"heart_disease_uci.csv\")\n",
    "\n",
    "# limit which rows are read when reading in a file\n",
    "pd.read_csv(\"heart_disease_uci.csv\", nrows=3)  # it will only read first 3 rows\n",
    "pd.read_csv(\n",
    "    \"heart_disease_uci.csv\", skiprows=[1, 4]\n",
    ")  # it will skip 1st row(i.e. row-index=0) & 4th row(i.e. row-index=3)\n",
    "\n",
    "# randomly sample a dataframe\n",
    "duffer_1 = df.sample(frac=0.62, random_state=1)  # it will contain 62% of the rows\n",
    "print(duffer_1)\n",
    "# this sample() randomly picks rows from df, like sufflinf a deck of cards\n",
    "# And Without random_state=1 we'll get differetn rows everytime but with it we'll get same rows every time\n",
    "duffer_2 = df[\n",
    "    ~df.index.isin(duffer_1.index)\n",
    "]  # it will contain the other 38% of the rows\n",
    "print(duffer_2)\n",
    "\n",
    "# # changing the maximum number of rows and columns printed\n",
    "# pd.set_option(max_columns, None)  # 'None' means 'unlimited'\n",
    "# # default is 60 rows\n",
    "\n",
    "# pd.set_option(max_columns, None)\n",
    "# # default is 60 columns\n",
    "\n",
    "# # Reset options to defaults\n",
    "# pd.reset_option(max_rows)\n",
    "# pd.reset_option(max_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e7ad1b",
   "metadata": {},
   "source": [
    "## Create DataFrame :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of pandas series\n",
    "items = {\n",
    "    \"Miku\": pd.Series(data=[100, 33, 181], index=[\"Watches\", \"shoes\", \"books\"]),\n",
    "    \"Milan\": pd.Series(data=[43, 22, 90], index=[\"toys\", \"shoes\", \"bats\"]),\n",
    "    \"Nikita\": pd.Series(data=[90, 28, 187], index=[\"makeup-kit\", \"sarees\", \"books\"]),\n",
    "}\n",
    "\n",
    "print(type(items))  # <class 'dict'>\n",
    "\n",
    "# creating a pandas DataFrame by passing it a dictionary of Series\n",
    "amazon_cart = pd.DataFrame(items)\n",
    "\n",
    "# creating dataframe that only has a subset of the data/colums\n",
    "shoes_shopping_cart = pd.DataFrame(\n",
    "    items, columns=[\"Milan\"]\n",
    ")  # will show everything of 'Milan' column only\n",
    "\n",
    "# creating a dataframe that only has selected keys\n",
    "shopping_cart = pd.DataFrame(\n",
    "    items, index=[\"toys\", \"makeup-kit\"]\n",
    ")  # this will show only 'toys' & 'makeup-kit' index/row for all columns\n",
    "\n",
    "# combining both of the above - i.e. selected keys for selected columns\n",
    "Miku_Nikita_books_shoes_collection = pd.DataFrame(\n",
    "    items, columns=[\"Miku\", \"Nikita\"], index=[\"books\", \"shoes\"]\n",
    ")\n",
    "\n",
    "# Creating DataFrames from a dictionary of lists (arrays)\n",
    "# In this case, however, all the lists (arrays) in the dictionary must be of the same length\n",
    "\n",
    "# Creating a dictioonary of lists (arrays)\n",
    "data = {\"Integers\": [1, 2, 3], \"Floats\": [1.2, 3.4, 5.6]}\n",
    "\n",
    "# Now creating a dataframe using the above lists\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# creating a DataFrame & providing the row index for each row/key\n",
    "df = pd.DataFrame(data, index=[\"nums-1\", \"nums-2\", \"nums-3\"])\n",
    "\n",
    "# Creating DataFrames from a list of Python dictionaris\n",
    "# CReating a list of python dictionaries\n",
    "items2 = [\n",
    "    {\"t-shirts\": 5, \"full-shirts\": 2, \"watches\": 3},\n",
    "    {\"bikes\": 0, \"goggles\": 6, \"watches\": 2},\n",
    "]\n",
    "\n",
    "# Creating a DataFrame\n",
    "store_items2 = pd.DataFrame(items2)\n",
    "\n",
    "\n",
    "# Creating a DataFrame and providing th row index\n",
    "store_items2 = pd.DataFrame(items2, index=[\"store-1\", \"store-2\"])\n",
    "print(store_items2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222c3f",
   "metadata": {},
   "source": [
    "## Create df from Series, dicts :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaing dictionary from a bunch of Series/data\n",
    "books = pd.Series(\n",
    "    data=[\n",
    "        \"half-girlfriend\",\n",
    "        \"Of Mice and Men\",\n",
    "        \"Romeo and Juliet\",\n",
    "        \"The Time Machine\",\n",
    "        \"Alice in Wonderland\",\n",
    "    ]\n",
    ")\n",
    "authors = pd.Series(\n",
    "    data=[\n",
    "        \"Chetan Bhagat\",\n",
    "        \"John Steinbeck\",\n",
    "        \"William Shakespeare\",\n",
    "        \" H. G. Wells\",\n",
    "        \"Lewis Carroll\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "user_1 = pd.Series(data=[1.4, 4.5])\n",
    "user_2 = pd.Series(data=[3.5, 9.1, 1.1, 9.0])\n",
    "user_3 = pd.Series(data=[1.4, 5, np.nan, 4.2])\n",
    "user_4 = pd.Series(data=[4, 3.5, 6, 8])\n",
    "\n",
    "a_dict = {\n",
    "    \"Author\": authors,\n",
    "    \"Book Title\": books,\n",
    "    \"User_1\": user_1,\n",
    "    \"User_2\": user_2,\n",
    "    \"User_3\": user_3,\n",
    "    \"User_4\": user_4,\n",
    "}\n",
    "\n",
    "# Use the dictionary to create a Pandas DataFrame\n",
    "book_ratings = pd.DataFrame(a_dict)\n",
    "\n",
    "# convert to numpy array (remove the column names, get just the values to convert it into a numpy array)\n",
    "book_ratings_numpy = book_ratings.values\n",
    "book_ratings_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720fe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CReating a DataFrame from a dictionary\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"column_x\": [\"value-x1\", \"value-x2\", \"value-x3\"],\n",
    "        \"column_y\": [\"value-y1\", \"value-y2\", \"value-y3\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# creatign a DataFrame from a list of lists\n",
    "pd.DataFrame(\n",
    "    [[\"value_x1\", \"value_y1\"], [\"value_x2\", \"value_y2\"], [\"value_x3\", \"value_y3\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de8213",
   "metadata": {},
   "source": [
    "## Accessing Elements :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a419e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing elements :---\n",
    "# Accesing via col-label\n",
    "print(\"watches in each store:- \\n\", store_items2[[\"watches\"]])\n",
    "print(\"\\nt-shirts & goggles in each store:- \\n\", store_items2[[\"t-shirts\", \"goggles\"]])\n",
    "\n",
    "# Accessing via row-label\n",
    "print(\"\\nItems in store-1:-\\n\", store_items2.loc[[\"store-1\"]])\n",
    "\n",
    "# Accessing via both row & col label\n",
    "print(\"\\nfull-shirts in store-1:\", store_items2[\"full-shirts\"][\"store-1\"])\n",
    "\n",
    "# while accessing individual elements in a dataframe, the labels should always be provided with column label first, then row label\n",
    "# i.e. in the form dataframe[column][row]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b537224",
   "metadata": {},
   "source": [
    "## Modify Elements :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying elements\n",
    "# Adding new columns\n",
    "# addin it to the end of the DF)\n",
    "store_items2[\"suits\"] = [22, 46]\n",
    "\n",
    "# Adding new column via arithmatic operation between columns\n",
    "store_items2[\"laptop\"] = store_items2[\"suits\"] + store_items2[\"watches\"]\n",
    "\n",
    "# Adding new row\n",
    "# To add rows to our df, create a new df then concat it to the original df\n",
    "# creating a dictoinary from a list of python dictionaries\n",
    "new_items = [\n",
    "    {\n",
    "        \"t-shirts\": 20,\n",
    "        \"full-shirts\": 8,\n",
    "        \"watches\": 10,\n",
    "        \"bikes\": 12,\n",
    "        \"goggles\": 4,\n",
    "        \"suits\": 71,\n",
    "        \"laptop\": 21,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Now creating a new dataFrame with the new_items and providing index label as 'store_3\n",
    "new_store = pd.DataFrame(new_items, index=[\"store-3\"])\n",
    "\n",
    "# concating store-3 to our store_items2 DataFrame\n",
    "store_items2 = pd.concat([store_items2, new_store])\n",
    "\n",
    "# inserting a new column with label bikes rigth before the column with numerical index 4\n",
    "store_items2.insert(4, \"cars\", [2, 66, 5])\n",
    "\n",
    "print(store_items2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e4a89",
   "metadata": {},
   "source": [
    "## Deleting Element :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75571d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deleting element\n",
    "# # .pop() method only allos us to delete columns, while .drop() method can be used to delete both rows and columns by use of the axis keyword\n",
    "\n",
    "# # removing the t-shirts column\n",
    "# store_items2.pop(\"t-shirts\")\n",
    "\n",
    "# # removing the full-shirts and bikes columns\n",
    "# store_items2 = store_items2.drop([\"goggles\", \"suits\"], axis=1)\n",
    "\n",
    "# # removing the store-2 & store-1 rows\n",
    "# store_items2 = store_items2.drop([\"store-2\", \"store-1\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94eaefb1",
   "metadata": {},
   "source": [
    "## Rename the Row & Column labels :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the row and column labels\n",
    "# changing the column label\n",
    "store_items2 = store_items2.rename(columns={\"cars\": \"skateboards\"})\n",
    "\n",
    "# changing the row label\n",
    "store_items2 = store_items2.rename(index={\"store-3\":\"last-store\"})\n",
    "store_items2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43741948",
   "metadata": {},
   "source": [
    "## Change Index :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Index\n",
    "# store_items2 = store_items2.set_index(\"store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c85c9b3",
   "metadata": {},
   "source": [
    "## Dealing with NaN values (missing data) :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46beb071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with NaN values (missing data)\n",
    "\n",
    "# creating a list of python dictionaries\n",
    "items2 = [\n",
    "    {\"bikes\": 20, \"pants\": 30, \"watches\": 35, \"shirts\": 15, \"shoes\": 8, \"suits\": 45},\n",
    "    {\n",
    "        \"watches\": 10,\n",
    "        \"glasses\": 50,\n",
    "        \"bikes\": 15,\n",
    "        \"pants\": 5,\n",
    "        \"shirts\": 2,\n",
    "        \"shoes\": 5,\n",
    "        \"suits\": 7,\n",
    "    },\n",
    "    {\"bikes\": 20, \"pants\": 30, \"watches\": 35, \"glasses\": 4, \"shoes\": 10},\n",
    "]\n",
    "\n",
    "# Now creating a dataFrame and providing the row index\n",
    "store_items = pd.DataFrame(items2, index=[\"store-1\", \"store-2\", \"store-3\"])\n",
    "\n",
    "# Checking if there are any NaN values in our dataset\n",
    "# .any() performs an OR operation. If any of the values along the specified axis is True, this will return True .\n",
    "store_items.isnull().any()\n",
    "# output :---\n",
    "\"\"\"\n",
    "bikes      False\n",
    "pants      False\n",
    "watches    False\n",
    "shirts      True\n",
    "shoes      False\n",
    "suits       True\n",
    "glasses     True\n",
    "dtype: bool\n",
    "\"\"\"\n",
    "\n",
    "# Counting the number of NaN values in DatFrame\n",
    "numOfNaNs = store_items.isnull().sum().sum()\n",
    "\n",
    "# Counting the number os non-NaN values in dataFrame\n",
    "numOfNaNs = store_items.count()\n",
    "\n",
    "# Removing rows & columns from our DataFrame that contain any NaN values\n",
    "\n",
    "# Dropping any rows with NaN values\n",
    "store_items.dropna(axis=0)\n",
    "\n",
    "# dropping any columns with NaN values\n",
    "store_items.dropna(axis=1)\n",
    "\n",
    "# The original DataFrame is not modified by Default\n",
    "# To remove missing values from original df, use inplace = True\n",
    "store_items.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Replacing all NaN values with 0\n",
    "store_items.fillna(0)\n",
    "\n",
    "# FORWARD FILLING : replacing NaN values with previous values in the DF,\n",
    "# When replacing NaN values with forward filling, we can user previous values taken from columns of rows.\n",
    "# Replacing the values with the previous value in the colum\n",
    "store_items.fillna(method=\"ffill\", axis=0)\n",
    "\n",
    "# BACKWARD FILLING : replacing the NaN values with the values that go after them in the DF\n",
    "# Reaplcing NaN values with the next values in the row\n",
    "store_items.fillna(method=\"backfill\", axis=1)\n",
    "\n",
    "# Replacing NaN values by using linear interpolation using column values\n",
    "store_items.interpolate(method=\"linear\", axis=0)\n",
    "\n",
    "# The original DataFrame isn't modified\n",
    "# Replacing the NaN values in place by setting inplace = True inside function\n",
    "store_items.fillna(method=\"ffill\", axis=0, inplace=True)\n",
    "store_items.interpolate(method=\"linear\", axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a6f76",
   "metadata": {},
   "source": [
    "## head, tail, describe, max, memory_usage :---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcfff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.tail()\n",
    "df.describe()\n",
    "df.max() # prints max value in each column\n",
    "\n",
    "# Displaying the memory usage of a DataFrame\n",
    "# total usage\n",
    "df.info()\n",
    "\n",
    "# usage by usage\n",
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62234abf",
   "metadata": {},
   "source": [
    "## corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the co-relation between different columns\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e951a",
   "metadata": {},
   "source": [
    "## Groupby\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a65d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby\n",
    "data.groupby([\"Year\"])\n",
    "data.groupby([\"Year\"])[\"Salary\"]\n",
    "\n",
    "# display the average salary per year\n",
    "data.groupby([\"Year\"])[\"Salary\"].mean()\n",
    "\n",
    "# display the total salary each employee received in all the years they worked for the company\n",
    "data.groupby([\"Name\"])[\"Salary\"].sum()\n",
    "\n",
    "# group the data by Year and by Department\n",
    "data.groupby([\"Year\", \"Department\"])[\"Salary\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50052c81",
   "metadata": {},
   "source": [
    "## Replace Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace Values\n",
    "s = pd.Series([\"cat\", \"dog\", np.nan, \"rabbit\"])\n",
    "s.map({\"cat\": \"kitten\", \"dog\": \"puppy\"})\n",
    "# another e.g.\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa80f27c",
   "metadata": {},
   "source": [
    "## Reading Files :--\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cc6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in a file from local computer or directly from a URL\n",
    "\n",
    "# various file formats that can be read in out wrote out\n",
    "\"\"\" \n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "binary        Python Pickle Format   read_pickle       to_pickle\n",
    "SQL                   SQL             read_sql          to_sql\n",
    "SQL             Google Big Query      read_gbq          to_gbq\n",
    "\"\"\"\n",
    "\n",
    "# to read about different types of files, and further functionality of reading in files, visit: http://pandas.pydata.org/pandas-docs/version/0.20/io.html\n",
    "df = pd.read_csv(\"./access-code-password-recovery-code.csv\")\n",
    "df = pd.read_csv(\"https://cdn.wsform.com/wp-content/uploads/2021/05/currency.csv\")\n",
    "\n",
    "# when reading in tables, can specify separators, and note a column to be used as index separators can include tabs (“\\t”), commas(“,”), pipes (“|”), etc.\n",
    "df = pd.read_table(\n",
    "    \"https://cdn.wsform.com/wp-content/uploads/2021/05/currency.csv\", sep=\"|\"\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f70724",
   "metadata": {},
   "source": [
    "## Now we can do all the above DataFrame operations in the df created using csv file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
